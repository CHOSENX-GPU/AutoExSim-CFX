# CFXè‡ªåŠ¨åŒ–è®¡ç®—ç³»ç»Ÿ

ä¸€ä¸ªå®Œæ•´çš„Python CFXè‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆï¼Œä¸“ä¸ºANSYS CFXè®¡ç®—æµä½“åŠ›å­¦(CFD)é›†ç¾¤ä½œä¸šç®¡ç†è€Œè®¾è®¡ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†**æ™ºèƒ½èŠ‚ç‚¹åˆ†é…ç­–ç•¥**ã€**å®æ—¶é›†ç¾¤çŠ¶æ€æŸ¥è¯¢**ã€**è‡ªåŠ¨è„šæœ¬ç”Ÿæˆ**ã€**æ’é˜Ÿç­–ç•¥ç®¡ç†**ã€**ä½œä¸šç›‘æ§**å’Œ**ç»“æœè‡ªåŠ¨ä¸‹è½½**ç­‰åŠŸèƒ½ï¼Œå…¨é¢æ”¯æŒPBSå’ŒSLURMè°ƒåº¦ç³»ç»Ÿã€‚

## ğŸ¯ ä¸»è¦åŠŸèƒ½

### ğŸ”¥ æ ¸å¿ƒç‰¹æ€§

- **ğŸ§  æ™ºèƒ½èŠ‚ç‚¹åˆ†é…**: å•èŠ‚ç‚¹ä¼˜å…ˆåˆ†é…ï¼Œé¿å…èµ„æºæµªè´¹ï¼ˆè§£å†³28æ ¸éœ€æ±‚è¢«åˆ†é…44æ ¸é—®é¢˜ï¼‰
- **ğŸ” å®æ—¶é›†ç¾¤æŸ¥è¯¢**: å‡†ç¡®è§£æPBSèŠ‚ç‚¹ä¿¡æ¯ï¼ˆnpå­—æ®µä¼˜å…ˆï¼Œä¿®å¤æ ¸å¿ƒæ•°é”™è¯¯é—®é¢˜ï¼‰
- **ğŸ“Š æ™ºèƒ½æ’é˜Ÿç­–ç•¥**: 3ç§æ’é˜Ÿç­–ç•¥ï¼ˆparallel/sequential/batchï¼‰è‡ªåŠ¨é€‚åº”èŠ‚ç‚¹èµ„æº
- **ğŸ“„ å¤šè°ƒåº¦å™¨æ”¯æŒ**: å®Œæ•´æ”¯æŒPBS/SLURMï¼Œè‡ªåŠ¨ç”Ÿæˆæ­£ç¡®çš„æäº¤è„šæœ¬
- **ğŸš€ ä¸€é”®å¼å·¥ä½œæµç¨‹**: è¿æ¥â†’æŸ¥è¯¢â†’åˆ†é…â†’ç”Ÿæˆâ†’æäº¤â†’ç›‘æ§
- **ğŸ’» ç”¨æˆ·å‹å¥½ç•Œé¢**: å‘½ä»¤è¡Œå·¥å…·å’ŒYAMLé…ç½®æ–‡ä»¶ç®¡ç†
- **ğŸ”§ Unixå…¼å®¹æ€§**: PBSè„šæœ¬ä½¿ç”¨Unixæ¢è¡Œç¬¦ï¼Œè§£å†³DOS/Windowsæ ¼å¼é—®é¢˜

### ğŸ¯ æ’é˜Ÿç­–ç•¥æ™ºèƒ½ç®¡ç†

- **ğŸ“‹ Parallelç­–ç•¥**: èŠ‚ç‚¹å……è¶³æ—¶ï¼Œæ¯ä¸ªä½œä¸šåˆ†é…ç‹¬ç«‹èŠ‚ç‚¹
- **âš¡ Sequentialç­–ç•¥**: èŠ‚ç‚¹ä¸è¶³æ—¶ï¼Œä½œä¸šä¾æ¬¡æ‰§è¡Œé¿å…å†²çª
- **ğŸ“¦ Batchç­–ç•¥**: å¤§é‡ä½œä¸šæ—¶ï¼Œåˆ†æ‰¹å¤„ç†ä¼˜åŒ–èµ„æºåˆ©ç”¨
- **ğŸ¤– è‡ªåŠ¨ç­–ç•¥é€‰æ‹©**: æ ¹æ®å¯ç”¨èŠ‚ç‚¹æ•°å’Œä½œä¸šæ•°é‡æ™ºèƒ½é€‰æ‹©æœ€ä¼˜ç­–ç•¥
- **ğŸ”„ åŠ¨æ€èŠ‚ç‚¹è¿½è¸ª**: å®æ—¶æ›´æ–°å·²åˆ†é…èŠ‚ç‚¹ï¼Œé¿å…é‡å¤åˆ†é…
- **âš–ï¸ è´Ÿè½½å‡è¡¡**: æ™ºèƒ½åˆ†æ•£ä½œä¸šåˆ°ä¸åŒèŠ‚ç‚¹ï¼Œæé«˜å¹¶è¡Œæ•ˆç‡

### ğŸ”„ ä½œä¸šç›‘æ§ä¸ç»“æœç®¡ç†

- **ğŸ¯ æ™ºèƒ½ä½œä¸šç›‘æ§**: è‡ªåŠ¨æ£€æµ‹ä½œä¸šå®ŒæˆçŠ¶æ€ï¼Œæ”¯æŒPBS/SLURMåŒè°ƒåº¦ç³»ç»Ÿ
- **ğŸ“¦ è‡ªåŠ¨ç»“æœä¸‹è½½**: è®¡ç®—å®Œæˆåè‡ªåŠ¨ä¸‹è½½.resã€.outã€.logç­‰ç»“æœæ–‡ä»¶
- **ğŸ•’ çµæ´»ç›‘æ§ç­–ç•¥**: å¯é…ç½®ç›‘æ§é—´éš”ã€è¶…æ—¶æ—¶é—´å’Œæ–‡ä»¶ç±»å‹
- **ğŸ“ æœ¬åœ°ç›®å½•æ˜ å°„**: ç»“æœæ–‡ä»¶è‡ªåŠ¨ä¸‹è½½åˆ°å¯¹åº”çš„æœ¬åœ°ç›®å½•
- **ğŸ“‹ ç›‘æ§æŠ¥å‘Šç”Ÿæˆ**: ç”Ÿæˆè¯¦ç»†çš„ç›‘æ§æ—¥å¿—å’Œæ‰§è¡ŒæŠ¥å‘Š

### ğŸ› ï¸ CFXç¯å¢ƒç®¡ç†

- **æ™ºèƒ½CFXç¯å¢ƒæ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹æœ¬åœ°å’ŒæœåŠ¡å™¨CFXå®‰è£…
- **åŒç¯å¢ƒæ”¯æŒ**: æ”¯æŒæœ¬åœ°CFXç”Ÿæˆdefæ–‡ä»¶æˆ–å®Œå…¨æœåŠ¡å™¨CFXç¯å¢ƒ
- **å‚æ•°åŒ–æ‰¹é‡å¤„ç†**: åŸºäºå‹åŠ›å‚æ•°è‡ªåŠ¨ç”Ÿæˆå¤šä¸ªCFXç®—ä¾‹
- **æ–‡ä»¶ä¼ è¾“ç®¡ç†**: æ™ºèƒ½æ–‡ä»¶ä¸Šä¼ /ä¸‹è½½å’Œä¼ è¾“éªŒè¯
- **è·¨å¹³å°å…¼å®¹**: å¤„ç†Windowsï¼ˆæœ¬åœ°ï¼‰ä¸Linuxï¼ˆæœåŠ¡å™¨ï¼‰è·¯å¾„å·®å¼‚

## ğŸ“ é¡¹ç›®ç»“æ„

```text
CFX_Automation/
â”œâ”€â”€ src/                          # æºä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                 # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ cfx.py                    # CFXæ ¸å¿ƒåŠŸèƒ½
â”‚   â”œâ”€â”€ cluster_query.py          # é›†ç¾¤æŸ¥è¯¢ä¸èŠ‚ç‚¹åˆ†é…
â”‚   â”œâ”€â”€ script_generator.py       # æ™ºèƒ½è„šæœ¬ç”Ÿæˆ
â”‚   â”œâ”€â”€ transfer.py               # æ–‡ä»¶ä¼ è¾“ç®¡ç†
â”‚   â”œâ”€â”€ job_monitor.py            # ä½œä¸šç›‘æ§
â”‚   â”œâ”€â”€ workflow_orchestrator.py  # å·¥ä½œæµç¼–æ’
â”‚   â”œâ”€â”€ slurm.py                  # SLURMè°ƒåº¦å™¨æ”¯æŒ
â”‚   â””â”€â”€ utils/                    # å·¥å…·æ¨¡å—
â”‚       â””â”€â”€ cfx_detector.py       # CFXç¯å¢ƒæ£€æµ‹
â”œâ”€â”€ templates/                    # æ¨¡æ¿æ–‡ä»¶
â”‚   â”œâ”€â”€ create_def.pre.j2         # CFX Preè„šæœ¬æ¨¡æ¿
â”‚   â”œâ”€â”€ CFX_Group_Cluster.slurm.j2 # SLURMä½œä¸šæ¨¡æ¿
â”‚   â”œâ”€â”€ CFX_Group_PBS.pbs.j2      # PBSä½œä¸šæ¨¡æ¿
â”‚   â”œâ”€â”€ Submit_All.sh.j2          # æ‰¹é‡æäº¤è„šæœ¬æ¨¡æ¿
â”‚   â””â”€â”€ Submit_INI.sh.j2          # åˆå§‹åŒ–æäº¤æ¨¡æ¿
â”œâ”€â”€ config/                       # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ local_cfx_university.yaml # å­¦æ ¡é›†ç¾¤é…ç½®ï¼ˆPBSï¼‰
â”‚   â”œâ”€â”€ local_cfx_new_cluster.yaml # ç»„å†…æ–°é›†ç¾¤é…ç½®ï¼ˆSLURMï¼‰
â”‚   â”œâ”€â”€ local_cfx_old_cluster.yaml # ç»„å†…è€é›†ç¾¤é…ç½®ï¼ˆPBSï¼‰
â”‚   â””â”€â”€ queue_test_config.yaml    # æ’é˜Ÿç­–ç•¥æµ‹è¯•é…ç½®
â”œâ”€â”€ docs/                         # å®Œæ•´æ–‡æ¡£
â”‚   â”œâ”€â”€ USER_GUIDE.md            # ç”¨æˆ·æŒ‡å—
â”‚   â”œâ”€â”€ FEATURES.md              # åŠŸèƒ½ç‰¹æ€§
â”‚   â”œâ”€â”€ INSTALLATION.md          # å®‰è£…æŒ‡å—
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # ç³»ç»Ÿæ¶æ„
â”‚   â””â”€â”€ ...                     # æ›´å¤šæ–‡æ¡£
â”œâ”€â”€ tests/                        # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ report/                       # æ‰§è¡ŒæŠ¥å‘Š
â”œâ”€â”€ main.py                       # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ requirements.txt              # ä¾èµ–åŒ…
â””â”€â”€ README.md                     # é¡¹ç›®è¯´æ˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/CHOSENX-GPU/AutoExSim-CFX.git
cd AutoExSim-CFX

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. é…ç½®è®¾ç½®

è¿è¡Œç¨‹åºåˆ›å»ºç¤ºä¾‹é…ç½®ï¼š

```bash
python main.py
```

é€‰æ‹© `y` åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶ï¼Œç„¶åç¼–è¾‘ `config/` ç›®å½•ä¸‹çš„é…ç½®æ–‡ä»¶ï¼š

- `local_cfx_university.yaml` - å­¦æ ¡é›†ç¾¤é…ç½®ï¼ˆPBSè°ƒåº¦å™¨ï¼‰
- `local_cfx_new_cluster.yaml` - ç»„å†…æ–°é›†ç¾¤é…ç½®ï¼ˆSLURMè°ƒåº¦å™¨ï¼‰
- `local_cfx_old_cluster.yaml` - ç»„å†…è€é›†ç¾¤é…ç½®ï¼ˆPBSè°ƒåº¦å™¨ï¼‰
- `queue_test_config.yaml` - æ’é˜Ÿç­–ç•¥æµ‹è¯•é…ç½®

### 3. æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º

#### ğŸ”§ æ™ºèƒ½èŠ‚ç‚¹åˆ†é…ä¸æ’é˜Ÿç­–ç•¥

```bash
# æµ‹è¯•æ™ºèƒ½æ’é˜Ÿç­–ç•¥ï¼ˆè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥ï¼‰
python main.py --run config/queue_test_config.yaml --steps connect_server query_cluster generate_scripts

# ä»…æŸ¥è¯¢é›†ç¾¤çŠ¶æ€ï¼ˆéªŒè¯èŠ‚ç‚¹ä¿¡æ¯ï¼‰
python main.py --run config/queue_test_config.yaml --steps connect_server query_cluster

# å•ç‹¬ç”Ÿæˆè„šæœ¬ï¼ˆæµ‹è¯•æ’é˜Ÿç­–ç•¥ï¼‰
python main.py --run config/queue_test_config.yaml --steps generate_scripts
```

**ç³»ç»Ÿè‡ªåŠ¨è§£å†³çš„é—®é¢˜ï¼š**

- âœ… **28æ ¸éœ€æ±‚è¢«åˆ†é…44æ ¸é—®é¢˜** â†’ æ™ºèƒ½å•èŠ‚ç‚¹ä¼˜å…ˆåˆ†é…
- âœ… **èŠ‚ç‚¹æ ¸å¿ƒæ•°æ£€æµ‹é”™è¯¯** â†’ npå­—æ®µä¼˜å…ˆï¼Œé¿å…statusä¸­ncpusè¦†ç›–
- âœ… **èŠ‚ç‚¹ä¸è¶³æ—¶çš„æ’é˜Ÿç®¡ç†** â†’ 3ç§ç­–ç•¥è‡ªåŠ¨é€‚åº”ï¼ˆparallel/sequential/batchï¼‰
- âœ… **PBSè„šæœ¬DOSæ ¼å¼é—®é¢˜** â†’ å¼ºåˆ¶Unixæ¢è¡Œç¬¦ï¼Œé¿å…æäº¤é”™è¯¯

#### ğŸ“Š æ’é˜Ÿç­–ç•¥è¯¦è§£

- **Parallelç­–ç•¥**: èŠ‚ç‚¹å……è¶³æ—¶ï¼Œæ¯ä¸ªä½œä¸šç‹¬ç«‹èŠ‚ç‚¹
- **Sequentialç­–ç•¥**: èŠ‚ç‚¹ä¸è¶³æ—¶ï¼Œä½œä¸šä¾æ¬¡æ‰§è¡Œ
- **Batchç­–ç•¥**: å¤§é‡ä½œä¸šæ—¶ï¼Œåˆ†æ‰¹å¤„ç†ï¼ˆå¦‚4ä½œä¸šåˆ†2æ‰¹ï¼‰

### 4. åŸºæœ¬ä½¿ç”¨

```bash
# ä½¿ç”¨å‹åŠ›å‚æ•°åˆ—è¡¨è¿è¡Œ
python main.py --config config/local_cfx_university.yaml --pressures 2187 2189 2191

# ä½¿ç”¨ä½œä¸šé…ç½®æ–‡ä»¶è¿è¡Œ
python main.py --config config/local_cfx_new_cluster.yaml --jobs example_jobs.json

# å•æ­¥æ‰§è¡Œï¼ˆè°ƒè¯•ç”¨ï¼‰
python main.py --config config.yaml --mode step --step query_cluster

# å¹²è¿è¡Œï¼ˆä»…ç”Ÿæˆè„šæœ¬ä¸æ‰§è¡Œï¼‰
python main.py --config config.yaml --pressures 2187 2189 --dry-run
```

## âš™ï¸ é…ç½®è¯´æ˜

### ä¸»è¦é…ç½®é¡¹

```yaml
# CFXç¯å¢ƒé…ç½®
cfx_mode: "local"                    # local/server - CFXè¿è¡Œæ¨¡å¼
auto_detect_cfx: true                # è‡ªåŠ¨æ£€æµ‹CFXè·¯å¾„
remote_cfx_home: "/opt/ansys_inc/v231/CFX"

# é›†ç¾¤é…ç½®
cluster_type: "university"           # university/group_new/group_old
scheduler_type: "PBS"                # SLURM/PBS
enable_node_detection: true          # æ˜¯å¦å¯ç”¨èŠ‚ç‚¹æ£€æµ‹
enable_node_allocation: true         # æ˜¯å¦å¯ç”¨æ™ºèƒ½åˆ†é…

# æœåŠ¡å™¨è¿æ¥
ssh_host: "cluster.university.edu"
ssh_user: "your_username"
remote_base_path: "/home/your_username/CFX_Jobs"

# ä½œä¸šå‚æ•°
pressure_list: [2187, 2189, 2191]   # å‹åŠ›å‚æ•°
partition: "cpu-low"                 # SLURMåˆ†åŒº
tasks_per_node: 28                   # æ¯èŠ‚ç‚¹ä»»åŠ¡æ•°ï¼ˆæ¨è28ï¼‰
min_cores: 28                        # æœ€å°æ ¸å¿ƒæ•°è¦æ±‚

# æ’é˜Ÿç­–ç•¥é…ç½®
queue_strategy_preference: "auto"    # auto/parallel/sequential/batch
force_queue_strategy: null           # å¼ºåˆ¶ä½¿ç”¨ç‰¹å®šç­–ç•¥ï¼ˆå¯é€‰ï¼‰
```

## ğŸ’¡ æ ¸å¿ƒç‰¹æ€§è¯¦è§£

### ğŸ§  æ™ºèƒ½èŠ‚ç‚¹åˆ†é…

ç³»ç»Ÿä¼šæ ¹æ®é›†ç¾¤å®é™…çŠ¶æ€å’Œä½œä¸šéœ€æ±‚ï¼Œæ™ºèƒ½é€‰æ‹©æœ€ä¼˜çš„èŠ‚ç‚¹åˆ†é…ç­–ç•¥ï¼š

#### åˆ†é…ä¼˜å…ˆçº§

1. **å•èŠ‚ç‚¹ä¼˜å…ˆ**: ä¼˜å…ˆé€‰æ‹©æ»¡è¶³éœ€æ±‚çš„å•èŠ‚ç‚¹ï¼ˆå¦‚28æ ¸â†’é€‰æ‹©28æ ¸èŠ‚ç‚¹ï¼‰
2. **é¿å…æµªè´¹**: é¿å…è¿‡åº¦åˆ†é…ï¼ˆ28æ ¸éœ€æ±‚ä¸ä¼šåˆ†é…åˆ°44æ ¸ï¼‰
3. **è´Ÿè½½å‡è¡¡**: æ™ºèƒ½åˆ†æ•£ä½œä¸šåˆ°ä¸åŒèŠ‚ç‚¹
4. **å®æ—¶æ›´æ–°**: åŠ¨æ€è¿½è¸ªå·²åˆ†é…èŠ‚ç‚¹ï¼Œé¿å…é‡å¤åˆ†é…

#### æ’é˜Ÿç­–ç•¥è‡ªåŠ¨é€‰æ‹©

```text
å¯ç”¨èŠ‚ç‚¹æ•° >= ä½œä¸šæ•°  â†’  Parallelç­–ç•¥ï¼ˆæ¯ä½œä¸šç‹¬ç«‹èŠ‚ç‚¹ï¼‰
å¯ç”¨èŠ‚ç‚¹æ•° < ä½œä¸šæ•°   â†’  Sequentialç­–ç•¥ï¼ˆä¾æ¬¡æ‰§è¡Œï¼‰
ä½œä¸šæ•° > 8ä¸ª         â†’  Batchç­–ç•¥ï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰
```

### ğŸ” å®æ—¶é›†ç¾¤æŸ¥è¯¢

#### PBSèŠ‚ç‚¹ä¿¡æ¯å‡†ç¡®è§£æ

```bash
# ä¿®å¤å‰ï¼šé”™è¯¯ä½¿ç”¨statusä¸­çš„ncpusï¼ˆå¯èƒ½æ˜¯56ï¼‰
# ä¿®å¤åï¼šä¼˜å…ˆä½¿ç”¨npå­—æ®µï¼ˆæ­£ç¡®çš„28ï¼‰

èŠ‚ç‚¹ä¿¡æ¯ï¼š
  name: n54
  np: 28          â† æ­£ç¡®çš„æ ¸å¿ƒæ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
  status: ncpus=56 â† é”™è¯¯çš„æ ¸å¿ƒæ•°ï¼ˆå¿½ç•¥ï¼‰
  state: free
```

#### é›†ç¾¤çŠ¶æ€å®æ—¶åŒæ­¥

- å®æ—¶æŸ¥è¯¢èŠ‚ç‚¹çŠ¶æ€ï¼ˆfree/allocated/downï¼‰
- å‡†ç¡®è·å–å¯ç”¨èŠ‚ç‚¹åˆ—è¡¨
- æ™ºèƒ½è¿‡æ»¤ä¸å¯ç”¨èŠ‚ç‚¹
- æ”¯æŒPBSå’ŒSLURMåŒè°ƒåº¦ç³»ç»Ÿ

### ğŸ“„ å¤šè°ƒåº¦å™¨è„šæœ¬ç”Ÿæˆ

#### PBSè°ƒåº¦å™¨æ”¯æŒ

```bash
# ç”ŸæˆPBSè„šæœ¬ï¼ˆ.pbsï¼‰
qsub job_2300.pbs

# æŸ¥çœ‹é˜Ÿåˆ—çŠ¶æ€
qstat -u $USER

# å–æ¶ˆä½œä¸š
qdel <JOB_ID>
```

#### SLURMè°ƒåº¦å™¨æ”¯æŒ

```bash
# ç”ŸæˆSLURMè„šæœ¬ï¼ˆ.slurmï¼‰
sbatch job_2300.slurm

# æŸ¥çœ‹é˜Ÿåˆ—çŠ¶æ€
squeue -u $USER

# å–æ¶ˆä½œä¸š
scancel <JOB_ID>
```

#### Unixå…¼å®¹æ€§

- æ‰€æœ‰è„šæœ¬ä½¿ç”¨Unixæ¢è¡Œç¬¦ï¼ˆLFï¼‰
- é¿å…"DOS/Windows text format"é”™è¯¯
- ç¡®ä¿PBS/SLURMæ­£ç¡®è¯†åˆ«è„šæœ¬æ ¼å¼

## ğŸ“Š ç›‘æ§ä¸æŠ¥å‘Š

### æ‰§è¡ŒæŠ¥å‘Š

ç³»ç»Ÿä¼šç”Ÿæˆè¯¦ç»†çš„æ‰§è¡ŒæŠ¥å‘Šï¼ŒåŒ…å«ï¼š

```json
{
  "execution_summary": {
    "total_jobs": 4,
    "successful_submissions": 4,
    "execution_duration_seconds": 45,
    "queue_strategy_used": "parallel",
    "nodes_allocated": ["n44", "n45", "n46", "n48"]
  },
  "cluster_status": {
    "total_nodes": 23,
    "available_nodes": 16,
    "node_allocation_efficiency": "100%"
  }
}
```

### ç›‘æ§æŠ¥å‘Š

ä½œä¸šç›‘æ§è¿‡ç¨‹ä¸­ç”Ÿæˆçš„æŠ¥å‘Šï¼š

```json
{
  "monitoring_summary": {
    "total_monitored_jobs": 4,
    "completed_jobs": 4,
    "failed_jobs": 0,
    "monitoring_duration": "2h 15m",
    "average_job_time": "32m"
  },
  "job_details": [
    {
      "job_id": "50198.hn",
      "pressure": 2300,
      "status": "completed",
      "runtime": "35m 12s",
      "node": "n44"
    }
  ]
}
```

## ğŸ”§ æ¨¡æ¿ç³»ç»Ÿ

### æ¨¡æ¿ç‰¹æ€§

ç³»ç»Ÿä½¿ç”¨Jinja2æ¨¡æ¿å¼•æ“ï¼Œæ”¯æŒï¼š

- åŠ¨æ€å‚æ•°æ›¿æ¢
- æ¡ä»¶é€»è¾‘ï¼ˆif/elseï¼‰
- å¾ªç¯ç»“æ„ï¼ˆfor loopsï¼‰
- æ¨¡æ¿ç»§æ‰¿
- è‡ªå®šä¹‰è¿‡æ»¤å™¨

#### å¯ç”¨æ¨¡æ¿

- `create_def.pre.j2` - CFX Preè„šæœ¬æ¨¡æ¿
- `CFX_Group_Cluster.slurm.j2` - SLURMä½œä¸šæ¨¡æ¿
- `CFX_Group_PBS.pbs.j2` - PBSä½œä¸šæ¨¡æ¿
- `Submit_All.sh.j2` - æ‰¹é‡æäº¤è„šæœ¬æ¨¡æ¿

#### åˆ›å»ºè‡ªå®šä¹‰æ¨¡æ¿

```bash
# å¤åˆ¶ç°æœ‰æ¨¡æ¿
cp templates/CFX_Group_PBS.pbs.j2 templates/my_custom.pbs.j2

# ç¼–è¾‘æ¨¡æ¿
nano templates/my_custom.pbs.j2

# åœ¨é…ç½®ä¸­æŒ‡å®šè‡ªå®šä¹‰æ¨¡æ¿
template_file: "my_custom.pbs.j2"
```

#### æ¨¡æ¿å‚æ•°ç¤ºä¾‹

```yaml
template_vars:
  pressure: 2300
  job_name: "CFX_Job_2300"
  walltime: "24:00:00"
  nodes: "n44:ppn=28"
  cfx_solver_path: "/opt/ansys_inc/v231/CFX/bin/cfx5solve"
  mpi_type: "Intel MPI Distributed Parallel"
```

## ğŸ“š æ–‡æ¡£

å®Œæ•´æ–‡æ¡£ä½äº `docs/` ç›®å½•ï¼š

- [ç”¨æˆ·æŒ‡å—](./docs/USER_GUIDE.md)
- [åŠŸèƒ½ç‰¹æ€§](./docs/FEATURES.md)
- [å®‰è£…æŒ‡å—](./docs/INSTALLATION.md)
- [ç³»ç»Ÿæ¶æ„](./docs/ARCHITECTURE.md)
- [æ¨¡æ¿æŒ‡å—](./docs/TEMPLATE_GUIDE.md)
- [æ•…éšœæ’é™¤](./docs/TROUBLESHOOTING.md)

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### é¡¹ç›®ä¾èµ–

```bash
pip install -r requirements.txt
```

ä¸»è¦ä¾èµ–åŒ…ï¼š

- `paramiko` - SSHè¿æ¥å’Œæ–‡ä»¶ä¼ è¾“
- `jinja2` - æ¨¡æ¿å¼•æ“
- `pyyaml` - YAMLé…ç½®æ–‡ä»¶è§£æ
- `requests` - HTTPè¯·æ±‚ï¼ˆå¯é€‰ï¼‰

### ä»£ç ç»“æ„

- `src/config.py` - é…ç½®ç®¡ç†å’ŒéªŒè¯
- `src/cluster_query.py` - é›†ç¾¤çŠ¶æ€æŸ¥è¯¢å’ŒèŠ‚ç‚¹åˆ†é…
- `src/script_generator.py` - æ™ºèƒ½è„šæœ¬ç”Ÿæˆ
- `src/workflow_orchestrator.py` - å·¥ä½œæµç¨‹ç¼–æ’

### æ‰©å±•å¼€å‘

è¦æ·»åŠ æ–°çš„è°ƒåº¦å™¨æ”¯æŒï¼š

1. åœ¨ `cluster_query.py` ä¸­æ·»åŠ æ–°çš„æŸ¥è¯¢æ–¹æ³•
2. åœ¨ `script_generator.py` ä¸­æ·»åŠ å¯¹åº”çš„è„šæœ¬ç”Ÿæˆé€»è¾‘
3. åˆ›å»ºç›¸åº”çš„æ¨¡æ¿æ–‡ä»¶
4. æ›´æ–°é…ç½®æ–‡ä»¶schema

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. èŠ‚ç‚¹åˆ†é…é—®é¢˜

**é—®é¢˜**: "28æ ¸éœ€æ±‚è¢«åˆ†é…44æ ¸"

**è§£å†³**: 
- å¯ç”¨æ™ºèƒ½åˆ†é…: `enable_node_allocation: true`
- è®¾ç½®æœ€å°æ ¸å¿ƒæ•°: `min_cores: 28`
- ç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©å•èŠ‚ç‚¹åˆ†é…

#### 2. PBSè„šæœ¬æ ¼å¼é”™è¯¯

**é—®é¢˜**: "qsub: script is written in DOS/Windows text format"

**è§£å†³**: 
- ç³»ç»Ÿå·²è‡ªåŠ¨ä¿®å¤ï¼Œä½¿ç”¨Unixæ¢è¡Œç¬¦
- ç¡®ä¿ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„è„šæœ¬ç”Ÿæˆå™¨

#### 3. æ’é˜Ÿç­–ç•¥é€‰æ‹©

**é—®é¢˜**: ä¸çŸ¥é“é€‰æ‹©å“ªç§æ’é˜Ÿç­–ç•¥

**è§£å†³**:
- ä½¿ç”¨ `queue_strategy_preference: "auto"`
- ç³»ç»Ÿä¼šæ ¹æ®é›†ç¾¤çŠ¶æ€è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç­–ç•¥

#### 4. é›†ç¾¤è¿æ¥é—®é¢˜

**é—®é¢˜**: SSHè¿æ¥å¤±è´¥

**è§£å†³**:
```yaml
# æ£€æŸ¥é…ç½®
ssh_host: "æ­£ç¡®çš„é›†ç¾¤åœ°å€"
ssh_user: "æ­£ç¡®çš„ç”¨æˆ·å"
ssh_password: "å¯†ç æˆ–ç•™ç©ºä½¿ç”¨å¯†é’¥"
ssh_key: "å¯†é’¥æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰"
```

### è°ƒè¯•æ¨¡å¼

```bash
# å•æ­¥æ‰§è¡Œ
python main.py --config config.yaml --steps connect_server
python main.py --config config.yaml --steps query_cluster
python main.py --config config.yaml --steps generate_scripts

# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
python main.py --config config.yaml --verbose
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

---

**CFXè‡ªåŠ¨åŒ–è®¡ç®—ç³»ç»Ÿ** - è®©CFXé›†ç¾¤è®¡ç®—æ›´ç®€å•ã€æ›´æ™ºèƒ½ï¼ğŸš€
